{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "governmental-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1\n",
      "numpy version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "framed-voltage",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (<ipython-input-2-194d81ae4c19>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-194d81ae4c19>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-corner",
   "metadata": {},
   "source": [
    "## Part 1: Tensor Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], \n",
    "                         dtype=torch.float32,\n",
    "                         device=device)\n",
    "print(my_tensor)\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.dtype)\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.shape)\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.size()) # identical to tensor.shape\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.device)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-shell",
   "metadata": {},
   "source": [
    "### Initialize from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(np_arr)\n",
    "print(type(np_arr))\n",
    "print(\"-----------------\")\n",
    "\n",
    "# numpy array to pytorch tensor\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "print(tensor)\n",
    "print(type(tensor))\n",
    "print(\"-----------------\")\n",
    "\n",
    "# pytorch tensor to numpy array\n",
    "np_arr_recovered = tensor.numpy()\n",
    "print(np_arr_recovered)\n",
    "print(type(np_arr_recovered))\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-tattoo",
   "metadata": {},
   "source": [
    "### tensor initializations for special tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "x = torch.zeros(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "x = torch.ones(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)[0,1)\n",
    "x = torch.rand(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 \n",
    "x = torch.randn(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Return an identity matrix\n",
    "x = torch.eye(5, 5)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Return a 1d tensor with specified start(inclusive), end(exsclusie), step size\n",
    "x = torch.arange(start=0, end=4, step=1)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Return a 1d tensor with specified start(inclusive), end(inclusive), number of points\n",
    "x = torch.linspace(start=0, end=10, steps=10)\n",
    "print(x)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-latest",
   "metadata": {},
   "source": [
    "### Inplace tensor initializations\n",
    "Note that any Pytorch method with an underscore(_) refers to an inplace operation, which means it will modify the existing object instead of creating a new copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialze a tensor filled with elements from standard normal in place \n",
    "x = torch.empty((2, 3)).normal_(mean=0, std=1)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# initialze a tensor filled with elements from unif(0, 1) in place \n",
    "x = torch.empty((2, 3)).uniform_(0, 1)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# fill a tensor with specified number (5)\n",
    "x = torch.ones((2, 3)).fill_(5)\n",
    "print(x)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-scanning",
   "metadata": {},
   "source": [
    "## Part 2: Type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default dtype: torch.int64\n",
    "x = torch.arange(1, 5, 1)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# convert to bool\n",
    "x_bool = x.bool()\n",
    "print(x_bool)\n",
    "print(x_bool.dtype)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# convert to float32 (most commonly used dtype)\n",
    "x_float = x.float()\n",
    "print(x_float)\n",
    "print(x_float.dtype)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# convert to float64\n",
    "x_double = x.double()\n",
    "print(x_double)\n",
    "print(x_double.dtype)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-bulgaria",
   "metadata": {},
   "source": [
    "## Part 3: Tensor Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 3, 5])\n",
    "y = torch.tensor([10, 8, 6])\n",
    "\n",
    "# addition\n",
    "z = x + y\n",
    "print(\"Addition\")\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# subtraction\n",
    "print(\"Subtraction\")\n",
    "z = x - y\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# multiplication (elementwise)\n",
    "print(\"Multiplication (elemenwise)\")\n",
    "z = x * y\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# division (elementwise)\n",
    "print(\"Division (elemenwise)\")\n",
    "z = x / y\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# dot product\n",
    "print(\"Dot product\")\n",
    "z = torch.dot(x, y)\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# exponentiation\n",
    "print(\"Exponentiation\")\n",
    "z = x ** 2 # same as x.pow(2)\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# logarithm - base equals e\n",
    "# input must be a torch.float dtype\n",
    "z = torch.log(x.float())\n",
    "print(z)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Multiplication\n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((5, 3))\n",
    "z = torch.mm(x1, x2) #2x3\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Matrix Multiplication\n",
    "batch = 32 \n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "x1 = torch.rand((batch, n, m))\n",
    "x2 = torch.rand((batch, m, p))\n",
    "z = torch.bmm(x1, x2) \n",
    "\n",
    "print(f\"x1 with shape {x1.shape}\")\n",
    "print(f\"x2 with shape {x2.shape}\")\n",
    "print(f\"z with shape {z.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, sum, max and other tensor operations\n",
    "x = torch.tensor([[-3, 8, 10], [8, 2, 6]])\n",
    "colsum_x = torch.sum(x, dim=0)\n",
    "print(\"torch sum\")\n",
    "print(colsum_x)\n",
    "print(\"-----------------\")\n",
    "rowsum_x = torch.sum(x, dim=1)\n",
    "print(rowsum_x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "rowmax_values, rowmax_indicies = torch.max(x, dim=1)\n",
    "print(\"torch max\")\n",
    "print(rowmax_values)\n",
    "print(rowmax_indicies)\n",
    "print(\"-----------------\")\n",
    "\n",
    "x_abs = torch.abs(x)\n",
    "print(\"torch abs\")\n",
    "print(x_abs)\n",
    "print(\"-----------------\")\n",
    "\n",
    "colmean_x = torch.mean(x.float(), dim=0)\n",
    "print(\"torch mean\")\n",
    "print(colmean_x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "\n",
    "x_clamped = torch.clamp(x, min=0, max=3)\n",
    "print(\"torch clamp\")\n",
    "print(x_clamped)\n",
    "print(\"-----------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-cambridge",
   "metadata": {},
   "source": [
    "## Part 4: Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand((3, 5))\n",
    "x2 = torch.rand((1, 5))\n",
    "\n",
    "# x2 will be firstly broadcasted to 3 by 5, then do the subtraction\n",
    "# broadcating applied here will copy the first row of x2 three times and stack them together\n",
    "z = x1 - x2\n",
    "\n",
    "print(f\"x1:\\n {x1}\")\n",
    "print(f\"x2:\\n {x2}\")\n",
    "print()\n",
    "print(\"Resulting tensor:\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix-vector multiplication\n",
    "x1 = torch.randn(4, 3)\n",
    "x2 = torch.randn(3)\n",
    "print(torch.matmul(x1, x2).shape)\n",
    "\n",
    "# matrix-vector multiplication\n",
    "x1 = torch.randn(4, 3)\n",
    "x2 = torch.randn(3)\n",
    "print(torch.matmul(x1, x2).shape)\n",
    "\n",
    "# batched matrix x broadcasted vector\n",
    "batch = 10\n",
    "x1 = torch.randn(batch, 3, 4)\n",
    "x2 = torch.randn(4) # [4] -> [4,1] -> [10, 4, 1]\n",
    "print(torch.matmul(x1, x2).shape) # [10, 3]\n",
    "\n",
    "# batched matrix x broadcasted matrix\n",
    "x1 = torch.randn(batch, 3, 4)\n",
    "x2 = torch.randn(4, 5) # [4, 5] -> [10, 4, 5]\n",
    "print(torch.matmul(x1, x2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-track",
   "metadata": {},
   "source": [
    "## Part 5: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 10\n",
    "num_features = 20\n",
    "\n",
    "x = torch.rand((batch, num_features))\n",
    "\n",
    "print(\"first sample:\")\n",
    "print(x[0]) #same as x[0, :]\n",
    "\n",
    "print(\"first feature\")\n",
    "print(x[:, 0])\n",
    "\n",
    "print(\"get first 10 features for the 3rd sample\")\n",
    "print(x[2, :10])\n",
    "\n",
    "# fancy indexing to access non-contiguous  locations of a tensor\n",
    "rows = torch.tensor([3, 5])\n",
    "cols = torch.tensor([2, 8])\n",
    "print(x[rows, cols])\n",
    "\n",
    "print(\"pick element with conditions\")\n",
    "x = torch.arange(10)\n",
    "print(x[(x<8) & (x>2)])\n",
    "print(x[x.remainder(2)==0])\n",
    "\n",
    "print(\"set values according to certain conditions\")\n",
    "print(torch.where(x>5, x, x*2)) # preserve the values if the value is greater than 5, other wise double it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-terminal",
   "metadata": {},
   "source": [
    "## Part 6: reshaping\n",
    "\n",
    "1. torch.view() can only work on conriguous tensors, while torch.reshape() can work on both\n",
    "2. torch.view() has performance advantage over torch.shape()\n",
    "2. if a tensor is not contiguous, you can still use **tensor.contiguous().view()** to reashape the tensor\n",
    "3. check this [post](https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107/2) if you are interested in what is the contiguous tensor in pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12) #(9)\n",
    "x_view = x.view((4, 3))\n",
    "print(x_view.shape)\n",
    "x_reshape = x.reshape((4, 3))\n",
    "print(x_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP this if it is too complicated\n",
    "# this involves how tensor is stored in the memory\n",
    "# contiguous tensor v.s. non-contiguous tensor\n",
    "# contiguous tensor: the stride size to move to the next column is 1\n",
    "x = torch.arange(12).view(4,3)\n",
    "print(x, x.stride(), x.is_contiguous())\n",
    "print(\"-----------------\")\n",
    "y = x.t()\n",
    "print(y, y.stride(), y.is_contiguous())\n",
    "\n",
    "# y.view(-1) # this does not work because we cannot use view() on a uncontiguous tensor\n",
    "y.contiguous().view(-1) # this will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate tensors \n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((2, 5))\n",
    "z = torch.cat((x1, x2), dim=0)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the 2nd and 3rd dimension of feature matrix to a single dimension\n",
    "batch = 64\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(batch, -1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch the axis\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.permute(0, 2, 1) # keep the batch dimension the same and switch the other two dimensions\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dimension of size 1\n",
    "x = torch.arange(10)\n",
    "print(x.unsqueeze(0)) #[10] -> [1,10]\n",
    "print(x.unsqueeze(1)) #[10] -> [10,1]\n",
    "\n",
    "# remove a dimension of size 1\n",
    "x = torch.arange(10).reshape(1, 10)\n",
    "print(x.squeeze(0)) #[1, 10] -> [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-valuation",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "1. Create a 2D tensor (elements drawn from standatd normal) and then add a dimension of size 1 inserted at dimension 1\n",
    "2. Remove the extra dimension you just added to the previous tensor\n",
    "3. Create a random tensor of shape 5x3 uniformly drawn from the interval [3, 7)\n",
    "4. Retireve the indicies of all the non zero elements in the tensor torch.Tensor([1, 1, 2, 0, 3])\n",
    "5. Create a random tensor of size (3,1) and horizontally stack four copies together. (the result tensor shape is (3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-indie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_dev_kernel",
   "language": "python",
   "name": "torch_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
