{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "governmental-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1\n",
      "numpy version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "framed-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-corner",
   "metadata": {},
   "source": [
    "## Part 1: Tensor Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loaded-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n",
      "-----------------\n",
      "torch.float32\n",
      "-----------------\n",
      "torch.Size([2, 3])\n",
      "-----------------\n",
      "torch.Size([2, 3])\n",
      "-----------------\n",
      "cuda:0\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], \n",
    "                         dtype=torch.float32,\n",
    "                         device=device)\n",
    "print(my_tensor)\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.dtype)\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.shape)\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.size()) # identical to tensor.shape\n",
    "print(\"-----------------\")\n",
    "print(my_tensor.device)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-shell",
   "metadata": {},
   "source": [
    "### Initialize from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rotary-belarus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "<class 'numpy.ndarray'>\n",
      "-----------------\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "<class 'torch.Tensor'>\n",
      "-----------------\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "<class 'numpy.ndarray'>\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(np_arr)\n",
    "print(type(np_arr))\n",
    "print(\"-----------------\")\n",
    "\n",
    "# numpy array to pytorch tensor\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "print(tensor)\n",
    "print(type(tensor))\n",
    "print(\"-----------------\")\n",
    "\n",
    "# pytorch tensor to numpy array\n",
    "np_arr_recovered = tensor.numpy()\n",
    "print(np_arr_recovered)\n",
    "print(type(np_arr_recovered))\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-tattoo",
   "metadata": {},
   "source": [
    "### tensor initializations for special tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increased-membership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.8459e+33,  4.5769e-41],\n",
      "        [-4.8459e+33,  4.5769e-41]])\n",
      "-----------------\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "-----------------\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "-----------------\n",
      "tensor([[0.0934, 0.5841],\n",
      "        [0.5338, 0.0417]])\n",
      "-----------------\n",
      "tensor([[ 1.7444, -0.9748],\n",
      "        [ 0.5226, -0.1040]])\n",
      "-----------------\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "-----------------\n",
      "tensor([0, 1, 2, 3])\n",
      "-----------------\n",
      "tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
      "         8.8889, 10.0000])\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "x = torch.zeros(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "x = torch.ones(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)[0,1)\n",
    "x = torch.rand(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 \n",
    "x = torch.randn(size=(2,2))\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Return an identity matrix\n",
    "x = torch.eye(5, 5)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Return a 1d tensor with specified start(inclusive), end(exsclusie), step size\n",
    "x = torch.arange(start=0, end=4, step=1)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# Return a 1d tensor with specified start(inclusive), end(inclusive), number of points\n",
    "x = torch.linspace(start=0, end=10, steps=10)\n",
    "print(x)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-latest",
   "metadata": {},
   "source": [
    "### Inplace tensor initializations\n",
    "Note that any Pytorch method with an underscore(_) refers to an inplace operation, which means it will modify the existing object instead of creating a new copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "similar-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2112,  1.7383,  1.3828],\n",
      "        [-0.1862,  1.3239, -0.5895]])\n",
      "-----------------\n",
      "tensor([[0.2946, 0.3312, 0.1492],\n",
      "        [0.7610, 0.0212, 0.7822]])\n",
      "-----------------\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# initialze a tensor filled with elements from standard normal in place \n",
    "x = torch.empty((2, 3)).normal_(mean=0, std=1)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# initialze a tensor filled with elements from unif(0, 1) in place \n",
    "x = torch.empty((2, 3)).uniform_(0, 1)\n",
    "print(x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# fill a tensor with specified number (5)\n",
    "x = torch.ones((2, 3)).fill_(5)\n",
    "print(x)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-scanning",
   "metadata": {},
   "source": [
    "## Part 2: Type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arctic-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "torch.int64\n",
      "-----------------\n",
      "tensor([True, True, True, True])\n",
      "torch.bool\n",
      "-----------------\n",
      "tensor([1., 2., 3., 4.])\n",
      "torch.float32\n",
      "-----------------\n",
      "tensor([1., 2., 3., 4.], dtype=torch.float64)\n",
      "torch.float64\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# default dtype: torch.int64\n",
    "x = torch.arange(1, 5, 1)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# convert to bool\n",
    "x_bool = x.bool()\n",
    "print(x_bool)\n",
    "print(x_bool.dtype)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# convert to float32 (most commonly used dtype)\n",
    "x_float = x.float()\n",
    "print(x_float)\n",
    "print(x_float.dtype)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# convert to float64\n",
    "x_double = x.double()\n",
    "print(x_double)\n",
    "print(x_double.dtype)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-bulgaria",
   "metadata": {},
   "source": [
    "## Part 3: Tensor Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collectible-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition\n",
      "tensor([11, 11, 11])\n",
      "-----------------\n",
      "Subtraction\n",
      "tensor([-9, -5, -1])\n",
      "-----------------\n",
      "Multiplication (elemenwise)\n",
      "tensor([10, 24, 30])\n",
      "-----------------\n",
      "Division (elemenwise)\n",
      "tensor([0.1000, 0.3750, 0.8333])\n",
      "-----------------\n",
      "Dot product\n",
      "tensor(64)\n",
      "-----------------\n",
      "Exponentiation\n",
      "tensor([ 1,  9, 25])\n",
      "-----------------\n",
      "tensor([0.0000, 1.0986, 1.6094])\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 3, 5])\n",
    "y = torch.tensor([10, 8, 6])\n",
    "\n",
    "# addition\n",
    "z = x + y\n",
    "print(\"Addition\")\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# subtraction\n",
    "print(\"Subtraction\")\n",
    "z = x - y\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# multiplication (elementwise)\n",
    "print(\"Multiplication (elemenwise)\")\n",
    "z = x * y\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# division (elementwise)\n",
    "print(\"Division (elemenwise)\")\n",
    "z = x / y\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# dot product\n",
    "print(\"Dot product\")\n",
    "z = torch.dot(x, y)\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# exponentiation\n",
    "print(\"Exponentiation\")\n",
    "z = x ** 2 # same as x.pow(2)\n",
    "print(z)\n",
    "print(\"-----------------\")\n",
    "\n",
    "# logarithm - base equals e\n",
    "# input must be a torch.float dtype\n",
    "z = torch.log(x.float())\n",
    "print(z)\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enclosed-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2946, 0.8078, 1.5901],\n",
      "        [1.0035, 0.8410, 1.7482]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((5, 3))\n",
    "z = torch.mm(x1, x2) #2x3\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "standard-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 with shape torch.Size([32, 10, 20])\n",
      "x2 with shape torch.Size([32, 20, 30])\n",
      "z with shape torch.Size([32, 10, 30])\n"
     ]
    }
   ],
   "source": [
    "# Batch Matrix Multiplication\n",
    "batch = 32 \n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "x1 = torch.rand((batch, n, m))\n",
    "x2 = torch.rand((batch, m, p))\n",
    "z = torch.bmm(x1, x2) \n",
    "\n",
    "print(f\"x1 with shape {x1.shape}\")\n",
    "print(f\"x2 with shape {x2.shape}\")\n",
    "print(f\"z with shape {z.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "controlled-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch sum\n",
      "tensor([ 5, 10, 16])\n",
      "-----------------\n",
      "tensor([15, 16])\n",
      "-----------------\n",
      "torch max\n",
      "tensor([10,  8])\n",
      "tensor([2, 0])\n",
      "-----------------\n",
      "torch abs\n",
      "tensor([[ 3,  8, 10],\n",
      "        [ 8,  2,  6]])\n",
      "-----------------\n",
      "torch mean\n",
      "tensor([2.5000, 5.0000, 8.0000])\n",
      "-----------------\n",
      "torch clamp\n",
      "tensor([[0, 3, 3],\n",
      "        [3, 2, 3]])\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# mean, sum, max and other tensor operations\n",
    "x = torch.tensor([[-3, 8, 10], [8, 2, 6]])\n",
    "colsum_x = torch.sum(x, dim=0)\n",
    "print(\"torch sum\")\n",
    "print(colsum_x)\n",
    "print(\"-----------------\")\n",
    "rowsum_x = torch.sum(x, dim=1)\n",
    "print(rowsum_x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "rowmax_values, rowmax_indicies = torch.max(x, dim=1)\n",
    "print(\"torch max\")\n",
    "print(rowmax_values)\n",
    "print(rowmax_indicies)\n",
    "print(\"-----------------\")\n",
    "\n",
    "x_abs = torch.abs(x)\n",
    "print(\"torch abs\")\n",
    "print(x_abs)\n",
    "print(\"-----------------\")\n",
    "\n",
    "colmean_x = torch.mean(x.float(), dim=0)\n",
    "print(\"torch mean\")\n",
    "print(colmean_x)\n",
    "print(\"-----------------\")\n",
    "\n",
    "\n",
    "x_clamped = torch.clamp(x, min=0, max=3)\n",
    "print(\"torch clamp\")\n",
    "print(x_clamped)\n",
    "print(\"-----------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-cambridge",
   "metadata": {},
   "source": [
    "## Part 4: Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exotic-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1:\n",
      " tensor([[0.4702, 0.9837, 0.2890, 0.5532, 0.2231],\n",
      "        [0.3634, 0.8649, 0.7174, 0.4346, 0.8095],\n",
      "        [0.3419, 0.8653, 0.3957, 0.0176, 0.0251]])\n",
      "x2:\n",
      " tensor([[0.6013, 0.6400, 0.0012, 0.3504, 0.8916]])\n",
      "\n",
      "Resulting tensor:\n",
      "tensor([[-0.1311,  0.3438,  0.2878,  0.2028, -0.6686],\n",
      "        [-0.2379,  0.2249,  0.7162,  0.0842, -0.0821],\n",
      "        [-0.2593,  0.2253,  0.3945, -0.3328, -0.8665]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand((3, 5))\n",
    "x2 = torch.rand((1, 5))\n",
    "\n",
    "# x2 will be firstly broadcasted to 3 by 5, then do the subtraction\n",
    "# broadcating applied here will copy the first row of x2 three times and stack them together\n",
    "z = x1 - x2\n",
    "\n",
    "print(f\"x1:\\n {x1}\")\n",
    "print(f\"x2:\\n {x2}\")\n",
    "print()\n",
    "print(\"Resulting tensor:\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accompanied-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# matrix-vector multiplication\n",
    "x1 = torch.randn(4, 3)\n",
    "x2 = torch.randn(3)\n",
    "print(torch.matmul(x1, x2).shape)\n",
    "\n",
    "# matrix-vector multiplication\n",
    "x1 = torch.randn(4, 3)\n",
    "x2 = torch.randn(3)\n",
    "print(torch.matmul(x1, x2).shape)\n",
    "\n",
    "# batched matrix x broadcasted vector\n",
    "batch = 10\n",
    "x1 = torch.randn(batch, 3, 4)\n",
    "x2 = torch.randn(4) # [4] -> [4,1] -> [10, 4, 1]\n",
    "print(torch.matmul(x1, x2).shape) # [10, 3]\n",
    "\n",
    "# batched matrix x broadcasted matrix\n",
    "x1 = torch.randn(batch, 3, 4)\n",
    "x2 = torch.randn(4, 5) # [4, 5] -> [10, 4, 5]\n",
    "print(torch.matmul(x1, x2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-track",
   "metadata": {},
   "source": [
    "## Part 5: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "solved-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sample:\n",
      "tensor([0.5188, 0.3393, 0.4233, 0.2633, 0.2911, 0.2108, 0.1535, 0.8564, 0.3948,\n",
      "        0.9893, 0.1660, 0.7462, 0.3142, 0.5593, 0.4792, 0.9205, 0.8772, 0.0752,\n",
      "        0.6690, 0.9806])\n",
      "first feature\n",
      "tensor([0.5188, 0.4800, 0.2569, 0.4574, 0.9137, 0.1602, 0.3561, 0.7827, 0.6193,\n",
      "        0.1719])\n",
      "get first 10 features for the 3rd sample\n",
      "tensor([0.2569, 0.0329, 0.6235, 0.7829, 0.3106, 0.2548, 0.0604, 0.4609, 0.8152,\n",
      "        0.2571])\n",
      "tensor([0.2346, 0.6245])\n",
      "pick element with conditions\n",
      "tensor([3, 4, 5, 6, 7])\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "set values according to certain conditions\n",
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n"
     ]
    }
   ],
   "source": [
    "batch = 10\n",
    "num_features = 20\n",
    "\n",
    "x = torch.rand((batch, num_features))\n",
    "\n",
    "print(\"first sample:\")\n",
    "print(x[0]) #same as x[0, :]\n",
    "\n",
    "print(\"first feature\")\n",
    "print(x[:, 0])\n",
    "\n",
    "print(\"get first 10 features for the 3rd sample\")\n",
    "print(x[2, :10])\n",
    "\n",
    "# fancy indexing to access non-contiguous  locations of a tensor\n",
    "rows = torch.tensor([3, 5])\n",
    "cols = torch.tensor([2, 8])\n",
    "print(x[rows, cols])\n",
    "\n",
    "print(\"pick element with conditions\")\n",
    "x = torch.arange(10)\n",
    "print(x[(x<8) & (x>2)])\n",
    "print(x[x.remainder(2)==0])\n",
    "\n",
    "print(\"set values according to certain conditions\")\n",
    "print(torch.where(x>5, x, x*2)) # preserve the values if the value is greater than 5, other wise double it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-terminal",
   "metadata": {},
   "source": [
    "## Part 6: reshaping\n",
    "\n",
    "1. torch.view() can only work on **contiguous tensors**, while torch.reshape() can work on both\n",
    "2. torch.view() has performance advantage over torch.shape()\n",
    "2. if a tensor is not contiguous, you can still use **tensor.contiguous().view()** to reashape the tensor\n",
    "3. check this [post](https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107/2) if you are interested in what is the contiguous tensor in pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "thermal-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12) #(12)\n",
    "x_view = x.view((4, 3))\n",
    "print(x_view.shape)\n",
    "x_reshape = x.reshape((4, 3))\n",
    "print(x_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "naked-basketball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]]) (3, 1) True\n",
      "-----------------\n",
      "tensor([[ 0,  3,  6,  9],\n",
      "        [ 1,  4,  7, 10],\n",
      "        [ 2,  5,  8, 11]]) (1, 3) False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SKIP this if it is too complicated\n",
    "# this involves how tensor is stored in the memory\n",
    "# contiguous tensor v.s. non-contiguous tensor\n",
    "# contiguous tensor: the stride size to move to the next column is 1\n",
    "x = torch.arange(12).view(4,3)\n",
    "print(x, x.stride(), x.is_contiguous())\n",
    "print(\"-----------------\")\n",
    "y = x.t()\n",
    "print(y, y.stride(), y.is_contiguous())\n",
    "\n",
    "# y.view(-1) # this does not work because we cannot use view() on a uncontiguous tensor\n",
    "y.contiguous().view(-1) # this will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automated-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# concatenate tensors \n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((2, 5))\n",
    "z = torch.cat((x1, x2), dim=0)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cooked-cleaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# flatten the 2nd and 3rd dimension of feature matrix to a single dimension\n",
    "batch = 64\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(batch, -1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "composed-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# switch the axis\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.permute(0, 2, 1) # keep the batch dimension the same and switch the other two dimensions\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "communist-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# add a dimension of size 1\n",
    "x = torch.arange(10)\n",
    "print(x.unsqueeze(0)) #[10] -> [1,10]\n",
    "print(x.unsqueeze(1)) #[10] -> [10,1]\n",
    "\n",
    "# remove a dimension of size 1\n",
    "x = torch.arange(10).reshape(1, 10)\n",
    "print(x.squeeze(0)) #[1, 10] -> [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-valuation",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "1. Create a 2D tensor (elements drawn from standatd normal) and then add a dimension of size 1 inserted at dimension 1\n",
    "2. Remove the extra dimension you just added to the previous tensor\n",
    "3. Create a random tensor of shape 5x3 uniformly drawn from the interval [3, 7)\n",
    "4. Retrieve the indices of all the non-zero elements in the tensor torch.Tensor([1, 1, 2, 0, 3])\n",
    "5. Create a random tensor of size (3,1) and horizontally stack four copies together. (the result tensor shape is (3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-indie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_dev_kernel",
   "language": "python",
   "name": "torch_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
